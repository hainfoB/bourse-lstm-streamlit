import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import plotly.graph_objects as go
import re
import datetime
import os

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import keras_tuner as kt

import pandas_datareader.data as web

try:
    SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
    LOGO_PATH = os.path.join(SCRIPT_DIR, "logo.png")
    if not os.path.exists(LOGO_PATH):
        LOGO_PATH = "ğŸš€"
except NameError:
    LOGO_PATH = "logo.png"

# ==============================
# CONFIGURATION
# ==============================
st.set_page_config(
    page_title="Haithem Vision Predict V3.0",
    layout="wide",
    page_icon=LOGO_PATH,
)

# ==============================
# MULTILINGUE (i18n)
# ==============================
translations = {
    'fr': {
        'page_title': "ğŸš€ Haithem Vision Predict V3.0",
        'lang_select': "Langue",
        
        'navigation': "Navigation",
        'page_home': "Accueil (PrÃ©diction)",
        'page_faq': "FAQ (Comment Ã§a marche ?)",
        'page_contact': "Contactez-nous",

        'faq_title': "â“ FAQ - Guide d'utilisation",
        'faq_step1_title': "Ã‰tape 1 : Choisir la langue",
        'faq_step1_desc': "Utilisez le sÃ©lecteur en haut de la barre latÃ©rale pour choisir entre FranÃ§ais, English, ou Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.",
        'faq_step2_title': "Ã‰tape 2 : Naviguer entre les pages",
        'faq_step2_desc': "Utilisez le menu 'Navigation' pour basculer entre la page d'Accueil (l'outil de prÃ©diction), la FAQ (cette page), et la page Contact.",
        'faq_step3_title': "Ã‰tape 3 : SÃ©lectionner un actif (sur la page d'Accueil)",
        'faq_step3_desc': "Dans 'ParamÃ¨tres de Base', choisissez une 'CatÃ©gorie' (ex: Actions US) puis un 'Actif Ã  prÃ©dire' (ex: Apple).",
        'faq_step4_title': "Ã‰tape 4 : Choisir un horizon",
        'faq_step4_desc': "SÃ©lectionnez l' 'Horizon de prÃ©diction' (ex: 1 an). Cela dÃ©termine la durÃ©e de la prÃ©vision future et la quantitÃ© de donnÃ©es historiques utilisÃ©es pour l'entraÃ®nement.",
        'faq_step5_title': "Ã‰tape 5 : Lancer l'entraÃ®nement",
        'faq_step5_desc': "Cliquez sur le bouton 'ğŸš€ Optimiser et EntraÃ®ner le ModÃ¨le'. Vous pouvez ajuster les 'ParamÃ¨tres d'EntraÃ®nement' (complexitÃ©, essais) pour affiner le modÃ¨le, mais les rÃ©glages par dÃ©faut sont recommandÃ©s pour commencer.",
        'faq_step6_title': "Ã‰tape 6 : Analyser les rÃ©sultats",
        'faq_step6_desc': "Une fois l'entraÃ®nement terminÃ©, trois onglets apparaissent :\n- **ğŸ”¬ Performance ModÃ¨le :** Affiche les dÃ©tails du modÃ¨le et les courbes d'apprentissage.\n- **ğŸ“ Ã‰valuation Test :** Compare les prÃ©dictions du modÃ¨le aux donnÃ©es rÃ©elles (non vues) pour Ã©valuer sa prÃ©cision.\n- **ğŸ”® Projection Future :** Montre la prÃ©vision pour l'horizon choisi, avec une analyse et une option de tÃ©lÃ©chargement.",

        'contact_title': "Nous Contacter",
        'contact_info': "Pour toute question, collaboration ou support technique, veuillez contacter :",
        'contact_name': "AHMED HAITHEM BERKANE",
        'contact_job_title': "CONSULTANT, DEVELOPPEUR WEB ET IA",
        'contact_phone': "TÃ©lÃ©phone",
        'contact_email': "Email",
        'contact_address': "Adresse",
        
        'base_params': "âš™ï¸ ParamÃ¨tres de Base",
        'category': "CatÃ©gorie",
        'predict_asset': "Actif Ã  prÃ©dire",
        'horizon': "Horizon de prÃ©diction",
        'horizons': ["6 mois", "1 an", "3 ans", "5 ans"],
        'train_params': "ğŸ› ï¸ ParamÃ¨tres d'EntraÃ®nement",
        'model_complexity': "ComplexitÃ© du ModÃ¨le",
        'complexities': ["Simple (1 couche - Rapide)", "Complexe (2 couches - PrÃ©cis)"],
        'optim_trials': "Essais d'optimisation",
        'train_epochs': "Ã‰poques d'entraÃ®nement final",
        'hist_data': "ğŸ“Š DonnÃ©es historiques",
        'info_analysis': "Analyse basÃ©e sur le",
        'info_log_return': "Log-Retour de",
        'info_and': "et",
        'run_button': "ğŸš€ Optimiser et EntraÃ®ner le ModÃ¨le",
        'spinner_optim': "Optimisation en cours",
        'success_optim': "âœ… HyperparamÃ¨tres optimisÃ©s. EntraÃ®nement final en cours...",
        'spinner_train': "EntraÃ®nement final du meilleur modÃ¨le",
        'success_train': "âœ… ModÃ¨le optimisÃ© et entraÃ®nÃ© !",
        'tab_perf': "ğŸ”¬ Performance ModÃ¨le",
        'tab_eval': "ğŸ“ Ã‰valuation Test",
        'tab_proj': "ğŸ”® Projection Future",
        'perf_title': "DÃ©tails et Performance du ModÃ¨le",
        'hp_title': "HyperparamÃ¨tres Optimaux :",
        'hp_units': "UnitÃ©s (Couche 1)",
        'hp_units_2': "UnitÃ©s (Couche 2)",
        'hp_dropout': "Dropout (Couche 1)",
        'hp_dropout_2': "Dropout (Couche 2)",
        'hp_lr': "Learning Rate",
        'metrics_title': "MÃ©triques d'EntraÃ®nement Finales :",
        'metrics_val_loss': "Perte de Validation Finale (val_loss)",
        'metrics_val_mae': "Erreur de Validation Finale (val_mae)",
        'metrics_caption': "MÃ©triques basÃ©es sur les log-retours scalÃ©s.",
        'charts_title': "Courbes d'Apprentissage :",
        'chart_loss_title': "Ã‰volution de la Perte (MSE)",
        'chart_loss_train': "Train Loss (MSE)",
        'chart_loss_val': "Validation Loss (MSE)",
        'chart_mae_title': "Ã‰volution de l'Erreur Absolue Moyenne",
        'chart_mae_train': "Train MAE",
        'chart_mae_val': "Validation MAE",
        'eval_title': "Ã‰valuation sur le Jeu de Test (sur les PRIX)",
        'eval_rmse': "RMSE (sur Prix)",
        'eval_mae': "MAE (sur Prix)",
        'eval_chart_title': "Comparaison RÃ©el vs. PrÃ©dit (sur les Prix)",
        'eval_real': "Valeurs RÃ©elles (Prix)",
        'eval_pred': "PrÃ©dictions (Prix)",
        'eval_toggle': "Afficher le tableau des valeurs de test",
        'eval_error': "Ã‰chec de la recrÃ©ation des donnÃ©es de test pour l'Ã©valuation.",
        'align_error': "Erreur d'alignement des donnÃ©es lors de l'Ã©valuation.",
        'proj_title': "Projection Future",
        'proj_spinner': "GÃ©nÃ©ration des prÃ©visions...",
        'proj_chart_title': "Projection Future (basÃ©e sur Log-Retours)",
        'proj_hist': "Historique (Prix)",
        'proj_future': "PrÃ©vision Future (Prix)",
        'proj_analysis_title': "ğŸ’¬ Analyse de la Projection",
        'proj_download': "ğŸ“¥ TÃ©lÃ©charger les PrÃ©visions (CSV)",
        'comment_trend': "ğŸ“ˆ **Tendance Globale :** Le modÃ¨le projette",
        'comment_rise': "une **hausse** de",
        'comment_fall': "une **baisse** de",
        'comment_for': "pour",
        'comment_reaching': "atteignant environ",
        'comment_by': "d'ici le",
        'comment_q_trend': "ğŸ¯ **Prochain Trimestre :** Une valeur d'environ",
        'comment_q_expected': "est attendue pour la",
        'comment_q_end': "Fin Q",
        'data_error': "Une erreur est survenue lors du chargement des donnÃ©es",
        'prep_error_positive': "Aucune donnÃ©e positive trouvÃ©e pour le calcul des log-retours.",
        'prep_error_log': "Aucune donnÃ©e aprÃ¨s calcul des log-retours. L'ensemble est peut-Ãªtre trop petit.",
        'prep_error_seq': "Pas assez de donnÃ©es pour crÃ©er des sÃ©quences",
    },
    'en': {
        'page_title': "ğŸš€ Haithem Vision Predict V3.0",
        'lang_select': "Language",
        
        'navigation': "Navigation",
        'page_home': "Home (Prediction)",
        'page_faq': "FAQ (How it works)",
        'page_contact': "Contact Us",

        'faq_title': "â“ FAQ - User Guide",
        'faq_step1_title': "Step 1: Choose Language",
        'faq_step1_desc': "Use the selector at the top of the sidebar to choose between FranÃ§ais, English, or Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.",
        'faq_step2_title': "Step 2: Navigate Pages",
        'faq_step2_desc': "Use the 'Navigation' menu to switch between the Home page (the prediction tool), the FAQ (this page), and the Contact page.",
        'faq_step3_title': "Step 3: Select an Asset (on Home page)",
        'faq_step3_desc': "Under 'Base Parameters', choose a 'Category' (e.g., US Stocks) and then an 'Asset to Predict' (e.g., Apple).",
        'faq_step4_title': "Step 4: Choose a Horizon",
        'faq_step4_desc': "Select the 'Prediction Horizon' (e.g., 1 year). This determines the length of the future forecast and the amount of historical data used for training.",
        'faq_step5_title': "Step 5: Run the Training",
        'faq_step5_desc': "Click the 'ğŸš€ Optimize and Train Model' button. You can adjust the 'Training Parameters' (complexity, trials) to fine-tune the model, but the default settings are recommended to start.",
        'faq_step6_title': "Step 6: Analyze the Results",
        'faq_step6_desc': "Once training is complete, three tabs will appear:\n- **ğŸ”¬ Model Performance:** Shows model details and learning curves.\n- **ğŸ“ Test Evaluation:** Compares the model's predictions against real (unseen) data to evaluate its accuracy.\n- **ğŸ”® Future Projection:** Displays the forecast for your chosen horizon, with analysis and a download option.",

        'contact_title': "Contact Us",
        'contact_info': "For any questions, collaboration, or technical support, please contact:",
        'contact_name': "AHMED HAITHEM BERKANE",
        'contact_job_title': "CONSULTANT, DEVELOPPEUR WEB ET IA",
        'contact_phone': "Phone",
        'contact_email': "Email",
        'contact_address': "Address",

        'base_params': "âš™ï¸ Base Parameters",
        'category': "Category",
        'predict_asset': "Asset to Predict",
        'horizon': "Prediction Horizon",
        'horizons': ["6 months", "1 year", "3 years", "5 years"],
        'train_params': "ğŸ› ï¸ Training Parameters",
        'model_complexity': "Model Complexity",
        'complexities': ["Simple (1 layer - Fast)", "Complex (2 layers - Accurate)"],
        'optim_trials': "Optimization Trials",
        'train_epochs': "Final Training Epochs",
        'hist_data': "ğŸ“Š Historical Data",
        'info_analysis': "Analysis based on",
        'info_log_return': "Log-Return of",
        'info_and': "and",
        'run_button': "ğŸš€ Optimize and Train Model",
        'spinner_optim': "Optimizing",
        'success_optim': "âœ… Hyperparameters optimized. Final training in progress...",
        'spinner_train': "Final training of the best model",
        'success_train': "âœ… Model optimized and trained!",
        'tab_perf': "ğŸ”¬ Model Performance",
        'tab_eval': "ğŸ“ Test Evaluation",
        'tab_proj': "ğŸ”® Future Projection",
        'perf_title': "Model Details and Performance",
        'hp_title': "Optimal Hyperparameters:",
        'hp_units': "Units (Layer 1)",
        'hp_units_2': "Units (Layer 2)",
        'hp_dropout': "Dropout (Layer 1)",
        'hp_dropout_2': "Dropout (Layer 2)",
        'hp_lr': "Learning Rate",
        'metrics_title': "Final Training Metrics:",
        'metrics_val_loss': "Final Validation Loss (val_loss)",
        'metrics_val_mae': "Final Validation Error (val_mae)",
        'metrics_caption': "Metrics based on scaled log-returns.",
        'charts_title': "Learning Curves:",
        'chart_loss_title': "Loss (MSE) Evolution",
        'chart_loss_train': "Train Loss (MSE)",
        'chart_loss_val': "Validation Loss (MSE)",
        'chart_mae_title': "Mean Absolute Error Evolution",
        'chart_mae_train': "Train MAE",
        'chart_mae_val': "Validation MAE",
        'eval_title': "Evaluation on Test Set (on PRICES)",
        'eval_rmse': "RMSE (on Price)",
        'eval_mae': "MAE (on Price)",
        'eval_chart_title': "Real vs. Predicted (on Prices)",
        'eval_real': "Real Values (Price)",
        'eval_pred': "Predictions (Price)",
        'eval_toggle': "Show test values table",
        'eval_error': "Failed to recreate test data for evaluation.",
        'align_error': "Data alignment error during evaluation.",
        'proj_title': "Future Projection",
        'proj_spinner': "Generating predictions...",
        'proj_chart_title': "Future Projection (based on Log-Returns)",
        'proj_hist': "History (Price)",
        'proj_future': "Future Prediction (Price)",
        'proj_analysis_title': "ğŸ’¬ Projection Analysis",
        'proj_download': "ğŸ“¥ Download Predictions (CSV)",
        'comment_trend': "ğŸ“ˆ **Global Trend:** The model projects a",
        'comment_rise': "rise of",
        'comment_fall': "fall of",
        'comment_for': "for",
        'comment_reaching': "reaching approx.",
        'comment_by': "by",
        'comment_q_trend': "ğŸ¯ **Next Quarter:** A value of approx.",
        'comment_q_expected': "is expected for",
        'comment_q_end': "End Q",
        'data_error': "An error occurred while loading data",
        'prep_error_positive': "No positive data found for log-return calculation.",
        'prep_error_log': "No data after log-return calculation. Dataset might be too small.",
        'prep_error_seq': "Not enough data to create sequences",
    },
    'ar': {
        'page_title': "ğŸš€ Haithem Vision Predict V3.0",
        'lang_select': "Ø§Ù„Ù„ØºØ©",

        'navigation': "Ø§Ù„ØªÙ†Ù‚Ù„",
        'page_home': "Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Ø§Ù„ØªÙ†Ø¨Ø¤)",
        'page_faq': "Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© (ÙƒÙŠÙ ÙŠØ¹Ù…Ù„)",
        'page_contact': "Ø§ØªØµÙ„ Ø¨Ù†Ø§",

        'faq_title': "â“ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© - Ø¯Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…",
        'faq_step1_title': "Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù„ØºØ©",
        'faq_step1_desc': "Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø­Ø¯Ø¯ ÙÙŠ Ø£Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„Ø§Ø®ØªÙŠØ§Ø± Ø¨ÙŠÙ† Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©ØŒ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©ØŒ Ø£Ùˆ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.",
        'faq_step2_title': "Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø§Ù„ØªÙ†Ù‚Ù„ Ø¨ÙŠÙ† Ø§Ù„ØµÙØ­Ø§Øª",
        'faq_step2_desc': "Ø§Ø³ØªØ®Ø¯Ù… Ù‚Ø§Ø¦Ù…Ø© 'Ø§Ù„ØªÙ†Ù‚Ù„' Ù„Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¨ÙŠÙ† Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Ø£Ø¯Ø§Ø© Ø§Ù„ØªÙ†Ø¨Ø¤)ØŒ ØµÙØ­Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© (Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø©)ØŒ ÙˆØµÙØ­Ø© Ø§Ù„Ø§ØªØµØ§Ù„.",
        'faq_step3_title': "Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø§Ø®ØªÙŠØ§Ø± Ø£ØµÙ„ (ÙÙŠ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©)",
        'faq_step3_desc': "ØªØ­Øª 'Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©'ØŒ Ø§Ø®ØªØ± 'Ø§Ù„ÙØ¦Ø©' (Ù…Ø«Ù„: Ø£Ø³Ù‡Ù… Ø£Ù…Ø±ÙŠÙƒÙŠØ©) Ø«Ù… 'Ø§Ù„Ø£ØµÙ„ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙˆÙ‚Ø¹Ù‡' (Ù…Ø«Ù„: Ø¢Ø¨Ù„).",
        'faq_step4_title': "Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø§Ø®ØªÙŠØ§Ø± Ø£ÙÙ‚ Ø§Ù„ØªÙ†Ø¨Ø¤",
        'faq_step4_desc': "Ø§Ø®ØªØ± 'Ø£ÙÙ‚ Ø§Ù„ØªÙ†Ø¨Ø¤' (Ù…Ø«Ù„: Ø³Ù†Ø© ÙˆØ§Ø­Ø¯Ø©). Ù‡Ø°Ø§ ÙŠØ­Ø¯Ø¯ Ù…Ø¯Ø© Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ ÙˆÙƒÙ…ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨.",
        'faq_step5_title': "Ø§Ù„Ø®Ø·ÙˆØ© 5: Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨",
        'faq_step5_desc': "Ø§Ù†Ù‚Ø± Ø¹Ù„Ù‰ Ø²Ø± 'ğŸš€ ØªØ­Ø³ÙŠÙ† ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬'. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„ 'Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨' (Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ØŒ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª) Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ ÙˆÙ„ÙƒÙ† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§ Ù„Ù„Ø¨Ø¯Ø¡.",
        'faq_step6_title': "Ø§Ù„Ø®Ø·ÙˆØ© 6: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬",
        'faq_step6_desc': "Ø¨Ù…Ø¬Ø±Ø¯ Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ Ø³ØªØ¸Ù‡Ø± Ø«Ù„Ø§Ø« Ø¹Ù„Ø§Ù…Ø§Øª ØªØ¨ÙˆÙŠØ¨:\n- **ğŸ”¬ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:** ÙŠØ¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù….\n- **ğŸ“ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±:** ÙŠÙ‚Ø§Ø±Ù† ØªÙ†bØ¤Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© (Ø§Ù„ØªÙŠ Ù„Ù… ÙŠØ±Ù‡Ø§) Ù„ØªÙ‚ÙŠÙŠÙ… Ø¯Ù‚ØªÙ‡.\n- **ğŸ”® Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ:** ÙŠØ¹Ø±Ø¶ Ø§Ù„ØªÙ†Ø¨Ø¤ Ù„Ù„Ø£ÙÙ‚ Ø§Ù„Ù…Ø®ØªØ§Ø±ØŒ Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ ÙˆØ®ÙŠØ§Ø± Ù„Ù„ØªÙ†Ø²ÙŠÙ„.",

        'contact_title': "Ø§ØªØµÙ„ Ø¨Ù†Ø§",
        'contact_info': "Ù„Ø£ÙŠØ© Ø£Ø³Ø¦Ù„Ø©ØŒ ØªØ¹Ø§ÙˆÙ†ØŒ Ø£Ùˆ Ø¯Ø¹Ù… ÙÙ†ÙŠØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€:",
        'contact_name': "AHMED HAITHEM BERKANE",
        'contact_job_title': "CONSULTANT, DEVELOPPEUR WEB ET IA",
        'contact_phone': "Ø§Ù„Ù‡Ø§ØªÙ",
        'contact_email': "Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ",
        'contact_address': "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†",

        'base_params': "âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©",
        'category': "Ø§Ù„ÙØ¦Ø©",
        'predict_asset': "Ø§Ù„Ø£ØµÙ„ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙˆÙ‚Ø¹Ù‡",
        'horizon': "Ø£ÙÙ‚ Ø§Ù„ØªÙ†Ø¨Ø¤",
        'horizons': ["6 Ø£Ø´Ù‡Ø±", "Ø³Ù†Ø© ÙˆØ§Ø­Ø¯Ø©", "3 Ø³Ù†ÙˆØ§Øª", "5 Ø³Ù†ÙˆØ§Øª"],
        'train_params': "ğŸ› ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨",
        'model_complexity': "ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬",
        'complexities': ["Ø¨Ø³ÙŠØ· (Ø·Ø¨Ù‚Ø© ÙˆØ§Ø­Ø¯Ø© - Ø³Ø±ÙŠØ¹)", "Ù…Ø¹Ù‚Ø¯ (Ø·Ø¨Ù‚ØªÙŠÙ† - Ø¯Ù‚ÙŠÙ‚)"],
        'optim_trials': "Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†",
        'train_epochs': "Ù…Ø±Ø§Ø­Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©",
        'hist_data': "ğŸ“Š Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©",
        'info_analysis': "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰",
        'info_log_return': "Ù„ÙˆØºØ§Ø±ÙŠØªÙ… Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ù„Ù€",
        'info_and': "Ùˆ",
        'run_button': "ğŸš€ ØªØ­Ø³ÙŠÙ† ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬",
        'spinner_optim': "Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ø³ÙŠÙ†",
        'success_optim': "âœ… ØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª. Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ...",
        'spinner_train': "Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬",
        'success_train': "âœ… ØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªØ¯Ø±ÙŠØ¨Ù‡!",
        'tab_perf': "ğŸ”¬ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬",
        'tab_eval': "ğŸ“ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±",
        'tab_proj': "ğŸ”® Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ",
        'perf_title': "ØªÙØ§ØµÙŠÙ„ ÙˆØ£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬",
        'hp_title': ":Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ÙØ§Ø¦Ù‚Ø© Ø§Ù„Ù…Ø«Ù„Ù‰",
        'hp_units': "Ø§Ù„ÙˆØ­Ø¯Ø§Øª (Ø§Ù„Ø·Ø¨Ù‚Ø© 1)",
        'hp_units_2': "Ø§Ù„ÙˆØ­Ø¯Ø§Øª (Ø§Ù„Ø·Ø¨Ù‚Ø© 2)",
        'hp_dropout': "Ø§Ù„ØªØ³Ø±Ø¨ (Ø§Ù„Ø·Ø¨Ù‚Ø© 1)",
        'hp_dropout_2': "Ø§Ù„ØªØ³Ø±Ø¨ (Ø§Ù„Ø·Ø¨Ù‚Ø© 2)",
        'hp_lr': "Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…",
        'metrics_title': ":Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©",
        'metrics_val_loss': "Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© (val_loss)",
        'metrics_val_mae': "Ø®Ø·Ø£ Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (val_mae)",
        'metrics_caption': ".Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ù„ÙˆØºØ§Ø±ÙŠØªÙ… Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø§Ù„Ù…Ø¹Ø¯Ù„",
        'charts_title': ":Ù…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù…",
        'chart_loss_title': "ØªØ·ÙˆØ± Ø§Ù„Ø®Ø³Ø§Ø±Ø© (MSE)",
        'chart_loss_train': "Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (MSE)",
        'chart_loss_val': "Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªØ­Ù‚Ù‚ (MSE)",
        'chart_mae_title': "ØªØ·ÙˆØ± Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù…Ø·Ù„Ù‚",
        'chart_mae_train': "Ù…ØªÙˆØ³Ø· Ø®Ø·Ø£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (MAE)",
        'chart_mae_val': "Ù…ØªÙˆØ³Ø· Ø®Ø·Ø£ Ø§Ù„ØªØ­Ù‚Ù‚ (MAE)",
        'eval_title': "Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±)",
        'eval_rmse': "(RMSE) Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¹Ø±",
        'eval_mae': "(MAE) Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¹Ø±",
        'eval_chart_title': "Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„ÙØ¹Ù„ÙŠ ÙˆØ§Ù„Ù…ØªÙˆÙ‚Ø¹ (Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±)",
        'eval_real': "(Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© (Ø§Ù„Ø³Ø¹Ø±",
        'eval_pred': "(Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª (Ø§Ù„Ø³Ø¹Ø±",
        'eval_toggle': "Ø¥Ø¸Ù‡Ø§Ø± Ø¬Ø¯ÙˆÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±",
        'eval_error': "ÙØ´Ù„ ÙÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù„Ù„ØªÙ‚ÙŠÙŠÙ….",
        'align_error': "Ø®Ø·Ø£ ÙÙŠ Ù…Ø­Ø§Ø°Ø§Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ….",
        'proj_title': "Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ",
        'proj_spinner': "...Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª",
        'proj_chart_title': "Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ (Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ù„ÙˆØºØ§Ø±ÙŠØªÙ… Ø§Ù„Ø¹Ø§Ø¦Ø¯)",
        'proj_hist': "(Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø§Ù„Ø³Ø¹Ø±",
        'proj_future': "(Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ (Ø§Ù„Ø³Ø¹Ø±",
        'proj_analysis_title': "ğŸ’¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆÙ‚Ø¹",
        'proj_download': "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª (CSV)",
        'comment_trend': "ğŸ“ˆ **Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…:** ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬",
        'comment_rise': "Ø§Ø±ØªÙØ§Ø¹Ù‹Ø§ Ø¨Ù†Ø³Ø¨Ø©",
        'comment_fall': "Ø§Ù†Ø®ÙØ§Ø¶Ù‹Ø§ Ø¨Ù†Ø³Ø¨Ø©",
        'comment_for': "Ù„Ù€",
        'comment_reaching': "Ù„ÙŠØµÙ„ Ø¥Ù„Ù‰ Ø­ÙˆØ§Ù„ÙŠ",
        'comment_by': "Ø¨Ø­Ù„ÙˆÙ„",
        'comment_q_trend': "ğŸ¯ **Ø§Ù„Ø±Ø¨Ø¹ Ø§Ù„Ù‚Ø§Ø¯Ù…:** ÙŠÙØªÙˆÙ‚Ø¹ Ù‚ÙŠÙ…Ø© Ø­ÙˆØ§Ù„ÙŠ",
        'comment_q_expected': "Ù„Ù€",
        'comment_q_end': "Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø±Ø¨Ø¹",
        'data_error': "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
        'prep_error_positive': "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ¬Ø¨Ø© Ù„Ø­Ø³Ø§Ø¨ Ù„ÙˆØºØ§Ø±ÙŠØªÙ… Ø§Ù„Ø¹Ø§Ø¦Ø¯.",
        'prep_error_log': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø­Ø³Ø§Ø¨ Ù„ÙˆØºØ§Ø±ÙŠØªÙ… Ø§Ù„Ø¹Ø§Ø¦Ø¯. Ù‚Ø¯ ØªÙƒÙˆÙ† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØµØºÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§.",
        'prep_error_seq': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø¥Ù†Ø´Ø§Ø¡ ØªØ³Ù„Ø³Ù„Ø§Øª",
    }
}

if 'lang' not in st.session_state:
    st.session_state.lang = 'fr'

def t(key):
    return translations.get(st.session_state.lang, translations['fr']).get(key, key)

HORIZON_KEYS = ['6m', '1y', '3y', '5y']
HORIZON_MAP = {
    '6m': {"train_years": 2, "predict_days": 180},
    '1y': {"train_years": 3, "predict_days": 365},
    '3y': {"train_years": 7, "predict_days": 3*365},
    '5y': {"train_years": 10, "predict_days": 5*365},
}
COMPLEXITY_KEYS = ['simple', 'complex']
LOOK_BACK = 60
TARGET_COL_ORIG_NAME = "Original_Price"

CATEGORIES = {
    "ğŸŒ Indices Mondiaux (ETFs)": {
        "S&P 500": "SPY", "NASDAQ 100": "QQQ", "Dow Jones": "DIA", "MSCI World": "URTH",
        "CAC 40 (France)": "EWQ", "FTSE 100 (UK)": "EWU", "DAX (Allemagne)": "EWG", "Nikkei 225 (Japon)": "EWJ",
    },
    "ğŸ‡ºğŸ‡¸ Actions (US)": {
        "ğŸ Apple": "AAPL", "ğŸ’» Microsoft": "MSFT", "ğŸš— Tesla": "TSLA", "ğŸ“¦ Amazon": "AMZN",
        "Alphabet (Google)": "GOOGL", "NVIDIA": "NVDA",
    },
    "ğŸ‡¨ğŸ‡¦ Actions (Canada)": {
        "ğŸ¦ Royal Bank": "RY.TO", "ğŸ›ï¸ Shopify": "SHOP.TO", "ğŸ›¢ï¸ Enbridge": "ENB.TO",
    },
    "ğŸ‡«ğŸ‡· Actions (France)": {
        "ğŸ‘œ LVMH": "MC.PA", "ğŸ’… L'OrÃ©al": "OR.PA", "â›½ TotalEnergies": "TTE.PA",
    },
    "ğŸ‡¬ğŸ‡§ Actions (Royaume-Uni)": {
        "ğŸ›¢ï¸ Shell": "SHEL.L", "ğŸ’Š AstraZeneca": "AZN.L", "ğŸ¦ HSBC": "HSBA.L",
    },
    "ğŸ‡©ğŸ‡ª Actions (Allemagne)": {
        "ğŸ’» SAP": "SAP.DE", "ğŸ”© Siemens": "SIE.DE", "ğŸš— Volkswagen": "VOW3.DE",
    },
    "ğŸ‡¨ğŸ‡­ Actions (Suisse)": {
        "ğŸ« NestlÃ©": "NESN.SW", "âš•ï¸ Roche": "ROG.SW", " Novartis": "NOVN.SW",
    },
    "ğŸ‡¯ğŸ‡µ Actions (Japon)": {
        "ğŸš— Toyota": "7203.T", "ğŸ® Sony": "6758.T", "SoftBank": "9984.T",
    },
    "ğŸ‡¨ğŸ‡³ Actions (Chine & HK)": {
        "ğŸ¶ Kweichow Moutai": "600519.SS", "ğŸ›ï¸ Alibaba": "BABA", "ğŸ® Tencent": "0700.HK",
    },
    "ğŸ‡®ğŸ‡³ Actions (Inde)": {
        "Reliance Industries": "RELIANCE.NS", "Tata (TCS)": "TCS.NS", "HDFC Bank": "HDFCBANK.NS",
    },
    "ğŸ‡§ğŸ‡· Actions (BrÃ©sil)": {
        "ğŸ›¢ï¸ Petrobras": "PBR", "Vale": "VALE", "ğŸ¦ ItaÃº Unibanco": "ITUB",
    },
    "ğŸª™ Cryptomonnaies": {
        "Bitcoin": "BTC-USD", "Ethereum": "ETH-USD", "Ripple": "XRP-USD", "Cardano": "ADA-USD",
    },
    "ğŸ’± Forex (Taux de Change)": {
        "EUR/USD": "EURUSD=X", "USD/JPY": "JPY=X", "GBP/USD": "GBPUSD=X", "AUD/USD": "AUDUSD=X",
    },
    "â›ï¸ Ã‰nergies": {
        "PÃ©trole Brut WTI": "CL=F", "PÃ©trole Brent": "BZ=F", "Gaz Naturel": "NG=F",
    },
    "ğŸ’ MÃ©taux PrÃ©cieux & Industriels": {
        "ğŸ¥‡ Or": "GC=F", "ğŸ¥ˆ Argent": "SI=F", "Cuivre": "HG=F", "ğŸ’ Platine": "PL=F", "ğŸ’ Palladium": "PA=F",
    },
    "ğŸšœ Agriculture": {
        "ğŸŒ½ MaÃ¯s": "ZC=F", "ğŸŒ¾ BlÃ©": "ZW=F", "ğŸŒ± Soja": "ZS=F", "â˜• CafÃ©": "KC=F", "ğŸ¬ Sucre": "SB=F", "ğŸ§¶ Coton": "CT=F",
    },
    "ğŸ›ï¸ Ã‰conomie (FRED - US)": {
        "ğŸ“‰ Taux de chÃ´mage": "UNRATE", "ğŸ“ˆ PIB (GDP)": "GDP", "ğŸ’² Inflation (CPI)": "CPIAUCSL",
        "Taux d'intÃ©rÃªt 10 ans": "DGS10", "Masse MonÃ©taire M2": "M2SL",
    }
}

# ==============================
# CSS STYLING
# ==============================
CSS_STYLE = """
<style>
/* ArriÃ¨re-plan principal de l'application */
[data-testid="stAppViewContainer"] > .main {
    background-color: #FDF8E3; /* Beige */
}
/* Sidebar */
[data-testid="stSidebar"] {
    background-color: #0A2342; /* Bleu FoncÃ© */
}

/* --- DÃ‰BUT DE LA CORRECTION CSS --- */

/* Cible tous les textes (paragraphes) DANS la sidebar */
[data-testid="stSidebar"] p {
    color: #FDF8E3; /* Beige clair pour le texte */
}

/* Cible tous les labels de widgets (radio, selectbox, etc.) DANS la sidebar */
[data-testid="stSidebar"] label {
    color: #FDF8E3 !important; /* Beige clair, !important pour forcer */
}

/* Cible tous les en-tÃªtes (h1, h2, h3) DANS la sidebar */
[data-testid="stSidebar"] h1,
[data-testid="stSidebar"] h2,
[data-testid="stSidebar"] h3 {
    color: #FDF8E3; /* Beige clair pour le texte */
}

/* Cible spÃ©cifiquement le texte Ã  l'intÃ©rieur des selectbox (la valeur sÃ©lectionnÃ©e) */
[data-testid="stSidebar"] [data-testid="stSelectbox"] [data-testid="stMarkdownContainer"] p {
     color: #FDF8E3;
}

/* --- FIN DE LA CORRECTION CSS --- */


/* Titre principal */
h1 {
    color: #0A2342; /* Bleu FoncÃ© */
    font-weight: bold;
}
/* Sous-titres */
h2, h3 {
    color: #0A2342; /* Bleu FoncÃ© */
}
/* Bouton principal */
.stButton > button {
    background-color: #FF6B00; /* Orange */
    color: #FFFFFF; /* Texte blanc */
    border: none;
    border-radius: 5px;
    font-weight: bold;
    padding: 10px 20px;
}
.stButton > button:hover {
    background-color: #E05C00; /* Orange plus foncÃ© au survol */
}
/* Bouton de tÃ©lÃ©chargement */
.stDownloadButton > button {
    background-color: #0A2342; /* Bleu FoncÃ© */
    color: #FFFFFF;
}
.stDownloadButton > button:hover {
    background-color: #004A99; /* Bleu plus clair au survol */
}
/* BoÃ®te d'information */
[data-testid="stInfo"] {
    background-color: #E6F0F8; /* Bleu trÃ¨s clair */
    border: 1px solid #0A2342;
    color: #0A2342;
}
/* BoÃ®te de succÃ¨s */
[data-testid="stSuccess"] {
    background-color: #DFF0D8;
    color: #3C763D;
}
/* Style des onglets (Tabs) */
.stTabs [data-baseweb="tab"] {
    background-color: #F0F2F6; /* Fond d'onglet inactif */
    color: #0A2342;
}
.stTabs [data-baseweb="tab"][aria-selected="true"] {
    background-color: #FFFFFF;
    color: #FF6B00; /* Orange pour le texte de l'onglet actif */
    border-top: 2px solid #FF6B00;
}
/* Conteneurs "Carte" */
[data-testid="stVerticalBlockBorderWrapper"] {
    border: 1px solid #E0E0E0;
    border-radius: 10px;
    padding: 1rem;
    background-color: #FFFFFF; /* Fond blanc pour les cartes */
    box-shadow: 0 4px 8px rgba(0,0,0,0.05);
}
</style>
"""
st.markdown(CSS_STYLE, unsafe_allow_html=True)

RTL_CSS = """
<style>
body, .main, [data-testid="stSidebar"] {
    direction: rtl !important;
}
[data-testid="stSidebar"] .st-emotion-cache-16txtl3, 
[data-testid="stSidebar"] .st-emotion-cache-183lzff,
[data-testid="stSidebar"] .st-emotion-cache-1d8k8ss p,
[data-testid="stSidebar"] .st-emotion-cache-16idsys p {
    text-align: right !important;
}
[data-testid="stSidebar"] h1, 
[data-testid="stSidebar"] h2, 
[data-testid="stSidebar"] h3 {
    text-align: right !important;
}
h1, h2, h3, p {
    text-align: right !important;
}
[data-testid="stInfo"], [data-testid="stMetric"], [data-testid="stSuccess"], [data-testid="stError"] {
    text-align: right !important;
    direction: rtl !important;
}
.stButton > button {
    direction: ltr !important;
    text-align: right !important;
    padding-left: 1rem !important;
    padding-right: 2.5rem !important;
}
[data-testid="stSidebar"] [data-testid="stRadio"] {
    direction: ltr !important;
}
[data-testid="stSidebar"] [data-testid="stRadio"] label {
    margin-left: 0.5rem;
    margin-right: 0;
}
[data-testid="stTabs"] {
    width: 100%;
}
[data-testid="stTabs"] [role="tablist"] {
    justify-content: flex-end;
}
[data-testid="stMarkdownContainer"] p, [data-testid="stMarkdownContainer"] li {
     text-align: right !important;
     direction: rtl !important;
}
</style>
"""

if st.session_state.lang == 'ar':
    st.markdown(RTL_CSS, unsafe_allow_html=True)

# ==============================
# INTERFACE UTILISATEUR (SIDEBAR)
# ==============================

if isinstance(LOGO_PATH, str) and os.path.exists(LOGO_PATH):
    st.sidebar.image(LOGO_PATH, width=64)
else:
    st.sidebar.markdown(f"<h1 style='text-align: center; color: white;'>{LOGO_PATH}</h1>", unsafe_allow_html=True)

st.sidebar.write(t('lang_select') + ":")
cols = st.sidebar.columns(3)
if cols[0].button("ğŸ‡«ğŸ‡·", use_container_width=True):
    if st.session_state.lang != 'fr':
        st.session_state.lang = 'fr'
        st.rerun()
if cols[1].button("ğŸ‡¬ğŸ‡§", use_container_width=True):
    if st.session_state.lang != 'en':
        st.session_state.lang = 'en'
        st.rerun()
if cols[2].button("ğŸ‡©ğŸ‡¿", use_container_width=True):
    if st.session_state.lang != 'ar':
        st.session_state.lang = 'ar'
        st.rerun()

st.sidebar.divider()

page_options = {
    'home': t('page_home'),
    'faq': t('page_faq'),
    'contact': t('page_contact')
}
selected_page_key = st.sidebar.radio(
    t('navigation'),
    options=list(page_options.keys()),
    format_func=lambda key: page_options[key],
    key="page_selector"
)

# ==============================
# FONCTIONS (LOGIQUE INCHANGÃ‰E)
# ==============================
@st.cache_data
def load_data(symbol, sector, years_of_data):
    end_date = datetime.datetime.now()
    start_date = end_date - datetime.timedelta(days=365.25 * years_of_data)
    features = []
    if "FRED" in sector:
        df = web.DataReader(symbol, "fred", start_date, end_date)
        col_to_select = symbol
        features = [col_to_select]
    else:
        df = yf.download(symbol, start=start_date, end=end_date, interval="1d")
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = [col[0] if isinstance(col, tuple) else col for col in df.columns]
        col_to_select = 'Adj Close' if 'Adj Close' in df.columns else 'Close'
        features = [col_to_select]
        if 'Volume' in df.columns and df['Volume'].sum() > 0:
            features.append('Volume')
            df['Volume'] = np.log1p(df['Volume'])
    df = df[features].dropna()
    return df, col_to_select, features

def prepare_data(df, features):
    target_col_name = features[0]
    df_copy = df.copy()
    df_copy = df_copy[df_copy[target_col_name] > 0]
    if df_copy.empty:
        st.error(t('prep_error_positive'))
        return (None,) * 7
    df_copy[TARGET_COL_ORIG_NAME] = df_copy[target_col_name]
    df_copy[target_col_name] = np.log(df_copy[target_col_name] / df_copy[target_col_name].shift(1))
    df_copy = df_copy.dropna()
    if df_copy.empty:
        st.error(t('prep_error_log'))
        return (None,) * 7
    df_scaled = pd.DataFrame(index=df_copy.index)
    price_scaler = MinMaxScaler(feature_range=(0, 1))
    df_scaled[target_col_name] = price_scaler.fit_transform(df_copy[[target_col_name]])
    feature_scalers = {}
    if len(features) > 1:
        for feature in features[1:]:
            scaler = MinMaxScaler(feature_range=(0, 1))
            df_scaled[feature] = scaler.fit_transform(df_copy[[feature]])
            feature_scalers[feature] = scaler
    scaled_data = df_scaled.values
    X, y = [], []
    for i in range(LOOK_BACK, len(scaled_data)):
        X.append(scaled_data[i-LOOK_BACK:i, :])
        y.append(scaled_data[i, 0])
    X, y = np.array(X), np.array(y)
    if len(X) == 0:
        st.error(f"{t('prep_error_seq')} (Lookback = {LOOK_BACK}).")
        return (None,) * 7
    split = int(len(X) * 0.8)
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]
    return X_train, y_train, X_test, y_test, price_scaler, feature_scalers, df_copy

def build_model(hp, input_shape, complexity='Complexe'):
    model = keras.Sequential()
    if complexity == 'Complexe':
        model.add(layers.LSTM(units=hp.Int('units_1', 32, 256, 32), return_sequences=True, input_shape=input_shape, name='lstm_1'))
        model.add(layers.Dropout(hp.Float('dropout_1', 0.1, 0.5, 0.1), name='dropout_1'))
        model.add(layers.LSTM(units=hp.Int('units_2', 32, 256, 32), return_sequences=False, name='lstm_2'))
        model.add(layers.Dropout(hp.Float('dropout_2', 0.1, 0.5, 0.1), name='dropout_2'))
    else:
        model.add(layers.LSTM(units=hp.Int('units_1', 32, 256, 32), return_sequences=False, input_shape=input_shape, name='lstm_1'))
        model.add(layers.Dropout(hp.Float('dropout_1', 0.1, 0.5, 0.1), name='dropout_1'))
    model.add(layers.Dense(1, name='output_layer'))
    lr = hp.Float('learning_rate', min_value=1e-4, max_value=2e-3, sampling='log')
    model.compile(optimizer=keras.optimizers.Adam(lr), 
                   loss='mean_squared_error',
                   metrics=['mae']) 
    return model

def generate_prediction_commentary(start_price, df_future, symbol_name, t_func):
    try:
        end_price = df_future['PrÃ©vision'].iloc[-1]
        end_date = df_future.index[-1]
        total_change_pct = ((end_price / start_price) - 1) * 100
        if total_change_pct > 0:
            global_trend = f"{t_func('comment_rise')} **{total_change_pct:.2f}%**"
        else:
            global_trend = f"{t_func('comment_fall')} **{total_change_pct:.2f}%**"
        commentary = [f"{t_func('comment_trend')} {global_trend} {t_func('comment_for')} {symbol_name}, {t_func('comment_reaching')} **{end_price:.2f}** {t_func('comment_by')} {end_date.strftime('%d-%m-%Y')}."]
        today = datetime.datetime.now().date()
        q_targets = []
        for i in range(1, 5):
            next_q_year = today.year + (today.month + i*3 - 1) // 12
            next_q_month = (today.month + i*3 - 1) % 12 + 1
            if next_q_month <= 3: q_date = datetime.date(next_q_year, 3, 31)
            elif next_q_month <= 6: q_date = datetime.date(next_q_year, 6, 30)
            elif next_q_month <= 9: q_date = datetime.date(next_q_year, 9, 30)
            else: q_date = datetime.date(next_q_year, 12, 31)
            if q_date <= end_date.date():
                q_targets.append((q_date.strftime('%Y-%m-%d'), f"{t_func('comment_q_end')} { (q_date.month - 1) // 3 + 1 } {q_date.year}"))
        if q_targets:
            first_q_date_str, first_q_name = q_targets[0]
            try:
                q_price = df_future.asof(first_q_date_str)['PrÃ©vision']
                q_change_pct = ((q_price / start_price) - 1) * 100
                commentary.append(f"{t_func('comment_q_trend')} **{q_price:.2f}** (soit **{q_change_pct:+.2f}%**) {t_func('comment_q_expected')} **{first_q_name}**.")
            except (KeyError, TypeError, IndexError):
                pass
        return "\n\n".join(commentary)
    except Exception as e:
        return f"Erreur lors de la gÃ©nÃ©ration du commentaire : {e}"

# ==============================
# ROUTAGE DES PAGES
# ==============================
if selected_page_key == 'home':
    st.title(t('page_title'))
    horizon_options_display = t('horizons')
    complexity_options_display = t('complexities')
    st.sidebar.header(t('base_params'))
    sector_display = st.sidebar.selectbox(t('category'), list(CATEGORIES.keys()))
    symbol_name_display = st.sidebar.selectbox(t('predict_asset'), list(CATEGORIES[sector_display].keys()))
    symbol = CATEGORIES[sector_display][symbol_name_display]
    selected_horizon_display = st.sidebar.selectbox(t('horizon'), horizon_options_display)
    horizon_key = HORIZON_KEYS[horizon_options_display.index(selected_horizon_display)]
    train_years = HORIZON_MAP[horizon_key]["train_years"]
    future_days = HORIZON_MAP[horizon_key]["predict_days"]
    st.sidebar.header(t('train_params'))
    selected_complexity_display = st.sidebar.selectbox(t('model_complexity'), complexity_options_display, index=1)
    complexity_key = COMPLEXITY_KEYS[complexity_options_display.index(selected_complexity_display)]
    max_trials = st.sidebar.number_input(t('optim_trials'), 1, 20, 10, 1)
    epochs = st.sidebar.number_input(t('train_epochs'), 10, 100, 50, 5)

    try:
        df_original, target_col, features_used = load_data(symbol, sector_display, train_years)
        st.subheader(f"{t('hist_data')} - {symbol_name_display}")
        info_text = f"{t('info_analysis')} **{t('info_log_return')} {target_col}**"
        if len(features_used) > 1: info_text += f" {t('info_and')} **Log({', '.join(features_used[1:])})**."
        st.info(info_text)
        with st.container(border=True):
            st.line_chart(df_original[target_col])
        prep_results = prepare_data(df_original, features_used)
        if prep_results[0] is None:
            st.stop()
        X_train, y_train, X_test, y_test, price_scaler, feature_scalers, df_processed = prep_results
    except Exception as e:
        st.error(f"{t('data_error')}: {e}")
        st.stop()

    if st.button(t('run_button')):
        with st.spinner(f"{t('spinner_optim')} ({max_trials} {t('optim_trials').lower()})..."):
            input_shape = (X_train.shape[1], X_train.shape[2])
            complexity_arg = "Complexe" if "complex" in complexity_key else "Simple"
            tuner = kt.RandomSearch(
                lambda hp: build_model(hp, input_shape, complexity=complexity_arg),
                objective='val_loss', max_trials=max_trials, executions_per_trial=1,
                directory='kt_dir', project_name=f'project_{symbol}_{complexity_arg}', overwrite=True
            )
            tuner.search(X_train, y_train, epochs=20, validation_split=0.2, verbose=0,
                         callbacks=[keras.callbacks.EarlyStopping('val_loss', patience=5)])
            best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]
        st.success(t('success_optim'))
        with st.spinner(f"{t('spinner_train')} (max {epochs} {t('train_epochs').lower().split()[-1]})..."):
            best_model = tuner.hypermodel.build(best_hp)
            early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
            history = best_model.fit(
                X_train, y_train,
                epochs=epochs,
                validation_split=0.2,
                batch_size=32,
                callbacks=[early_stopping],
                verbose=0
            )
        st.success(t('success_train'))
        st.session_state['model'] = best_model
        st.session_state['history'] = history.history
        st.session_state['best_hp'] = best_hp
        st.session_state['price_scaler'] = price_scaler
        st.session_state['feature_scalers'] = feature_scalers
        st.session_state['df_original'] = df_original
        st.session_state['df_processed'] = df_processed
        st.session_state['features_used'] = features_used
        st.session_state['target_col'] = target_col
        st.session_state['trained_symbol'] = symbol
        st.session_state['trained_horizon'] = horizon_key
        st.session_state['trained_complexity'] = complexity_key

    is_model_stale = not ('model' in st.session_state and
                           st.session_state.get('trained_symbol') == symbol and
                           st.session_state.get('trained_horizon') == horizon_key and
                           st.session_state.get('trained_complexity') == complexity_key)

    if not is_model_stale:
        model = st.session_state['model']
        history_data = st.session_state['history']
        best_hp_data = st.session_state['best_hp']
        price_scaler = st.session_state['price_scaler']
        feature_scalers = st.session_state['feature_scalers']
        df_history_original = st.session_state['df_original']
        df_history_processed = st.session_state['df_processed']
        features_used = st.session_state['features_used']
        target_col = st.session_state['target_col']
        prep_results_full = prepare_data(df_history_original, features_used)
        if prep_results_full[0] is not None:
            _, _, _, _, _, _, df_processed_full = prep_results_full
            X_train_len = int(len(df_processed_full) * 0.8) - LOOK_BACK
        else:
            st.error("Impossible de recalculer les donnÃ©es pour l'affichage.")
            st.stop()

        tab_perf, tab_eval, tab_proj = st.tabs([
            t('tab_perf'), 
            t('tab_eval'), 
            t('tab_proj')
        ])
        with tab_perf:
            st.subheader(t('perf_title'))
            with st.container(border=True):
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**{t('hp_title')}**")
                    hp_md = f"- **{t('hp_units')}:** `{best_hp_data.get('units_1')}`\n"
                    hp_md += f"- **{t('hp_dropout')}:** `{best_hp_data.get('dropout_1'):.2f}`\n"
                    if complexity_key == 'complex':
                        hp_md += f"- **{t('hp_units_2')}:** `{best_hp_data.get('units_2')}`\n"
                        hp_md += f"- **{t('hp_dropout_2')}:** `{best_hp_data.get('dropout_2'):.2f}`\n"
                    hp_md += f"- **{t('hp_lr')}:** `{best_hp_data.get('learning_rate'):.6f}`"
                    st.markdown(hp_md, unsafe_allow_html=True if st.session_state.lang == 'ar' else False)
                with col2:
                    st.write(f"**{t('metrics_title')}**")
                    final_val_loss = history_data['val_loss'][-1]
                    final_val_mae = history_data['val_mae'][-1]
                    st.metric(t('metrics_val_loss'), f"{final_val_loss:.6f}")
                    st.metric(t('metrics_val_mae'), f"{final_val_mae:.6f}")
                    st.caption(t('metrics_caption'))
            st.write(f"**{t('charts_title')}**")
            with st.container(border=True):
                col1, col2 = st.columns(2)
                with col1:
                    fig_loss = go.Figure()
                    fig_loss.add_trace(go.Scatter(y=history_data['loss'], name=t('chart_loss_train'), line=dict(color='#0A2342')))
                    fig_loss.add_trace(go.Scatter(y=history_data['val_loss'], name=t('chart_loss_val'), line=dict(color='#FF6B00')))
                    fig_loss.update_layout(title=t('chart_loss_title'), xaxis_title='Ã‰poques', yaxis_title='Perte')
                    st.plotly_chart(fig_loss, use_container_width=True)
                with col2:
                    fig_mae = go.Figure()
                    fig_mae.add_trace(go.Scatter(y=history_data['mae'], name=t('chart_mae_train'), line=dict(color='#0A2342')))
                    fig_mae.add_trace(go.Scatter(y=history_data['val_mae'], name=t('chart_mae_val'), line=dict(color='#FF6B00')))
                    fig_mae.update_layout(title=t('chart_mae_title'), xaxis_title='Ã‰poques', yaxis_title='MAE')
                    st.plotly_chart(fig_mae, use_container_width=True)
        with tab_eval:
            st.subheader(t('eval_title'))
            prep_results_eval = prepare_data(df_history_original, features_used)
            if prep_results_eval[0] is None:
                st.error(t('eval_error'))
            else:
                _, _, X_test_eval, y_test_eval, _, _, df_processed_eval = prep_results_eval
                if len(X_test_eval) == 0:
                    st.warning("Pas assez de donnÃ©es pour un jeu de test. Essayez un horizon de donnÃ©es plus long.")
                else:
                    preds_scaled = model.predict(X_test_eval)
                    preds_log_returns = price_scaler.inverse_transform(preds_scaled)
                    test_start_index = X_train_len + LOOK_BACK
                    if test_start_index < len(df_processed_eval) and (test_start_index - 1) < len(df_processed_eval):
                        y_test_true_prices = df_processed_eval[TARGET_COL_ORIG_NAME].iloc[test_start_index:].values
                        y_test_previous_prices = df_processed_eval[TARGET_COL_ORIG_NAME].iloc[test_start_index - 1 : -1].values
                        if len(y_test_previous_prices) == len(preds_log_returns):
                            preds_rescaled = y_test_previous_prices * np.exp(preds_log_returns.flatten())
                            y_test_rescaled = y_test_true_prices
                            with st.container(border=True):
                                rmse = np.sqrt(mean_squared_error(y_test_rescaled, preds_rescaled))
                                mae = mean_absolute_error(y_test_rescaled, preds_rescaled)
                                col1, col2 = st.columns(2)
                                col1.metric(t('eval_rmse'), f"{rmse:.4f}")
                                col2.metric(t('eval_mae'), f"{mae:.4f}")
                            with st.container(border=True):
                                fig_compare = go.Figure()
                                test_dates = df_processed_eval.index[test_start_index:]
                                fig_compare.add_trace(go.Scatter(x=test_dates, y=y_test_rescaled.flatten(), mode='lines', name=t('eval_real'), line=dict(color='#0A2342')))
                                fig_compare.add_trace(go.Scatter(x=test_dates, y=preds_rescaled.flatten(), mode='lines', name=t('eval_pred'), line=dict(color='#FF6B00', dash='dash')))
                                fig_compare.update_layout(title_text=t('eval_chart_title'), hovermode="x unified")
                                st.plotly_chart(fig_compare, use_container_width=True)
                            if st.toggle(t('eval_toggle')):
                                results_df = pd.DataFrame({'Date': test_dates, 'Valeur RÃ©elle': y_test_rescaled.flatten(), 'PrÃ©diction': preds_rescaled.flatten()})
                                st.dataframe(results_df.set_index('Date'))
                        else:
                            st.error(t('align_error'))
                    else:
                        st.error("Erreur d'indexation lors de la crÃ©ation du jeu de test.")
        with tab_proj:
            st.subheader(f"{t('proj_title')} ({selected_horizon_display})")
            with st.spinner(t('proj_spinner')):
                last_60_days_processed = df_history_processed.iloc[-LOOK_BACK:]
                last_60_days_scaled = pd.DataFrame(index=last_60_days_processed.index)
                last_60_days_scaled[target_col] = price_scaler.transform(last_60_days_processed[[target_col]])
                for feature in features_used[1:]:
                    last_60_days_scaled[feature] = feature_scalers[feature].transform(last_60_days_processed[[feature]])
                current_batch = last_60_days_scaled.values.reshape(1, LOOK_BACK, len(features_used))
                future_preds_prices = []
                last_known_price = df_history_processed[TARGET_COL_ORIG_NAME].iloc[-1]
                for _ in range(future_days):
                    pred_scaled_log_return = model.predict(current_batch, verbose=0)[0]
                    pred_log_return = price_scaler.inverse_transform(pred_scaled_log_return.reshape(1, -1))
                    new_price = last_known_price * np.exp(pred_log_return[0, 0])
                    future_preds_prices.append(new_price)
                    last_known_price = new_price
                    new_entry = np.zeros((1, 1, len(features_used)))
                    new_entry[0, 0, 0] = pred_scaled_log_return[0]
                    if len(features_used) > 1:
                        for i, feature in enumerate(features_used[1:]):
                            mean_feature_val = current_batch[0, :, i+1].mean()
                            new_entry[0, 0, i+1] = mean_feature_val
                    current_batch = np.append(current_batch[:, 1:, :], new_entry, axis=1)
            future_preds_rescaled = np.array(future_preds_prices).flatten()
            future_dates = pd.date_range(start=df_history_processed.index[-1] + pd.Timedelta(days=1), periods=future_days, freq='B')
            df_future = pd.DataFrame(future_preds_rescaled, index=future_dates, columns=['PrÃ©vision'])
            with st.container(border=True):
                fig_future = go.Figure()
                fig_future.add_trace(go.Scatter(x=df_history_original.index, y=df_history_original[target_col], mode='lines', name=t('proj_hist'), line=dict(color='#0A2342')))
                fig_future.add_trace(go.Scatter(x=df_future.index, y=df_future['PrÃ©vision'], mode='lines', name=t('proj_future'), line=dict(color='#FF6B00', dash='dash')))
                fig_future.update_layout(title_text=t('proj_chart_title'), hovermode="x unified")
                st.plotly_chart(fig_future, use_container_width=True)
            st.subheader(t('proj_analysis_title'))
            with st.container(border=True):
                last_price = df_history_processed[TARGET_COL_ORIG_NAME].iloc[-1]
                comment_text = generate_prediction_commentary(last_price, df_future, symbol_name_display, t)
                st.markdown(comment_text, unsafe_allow_html=True if st.session_state.lang == 'ar' else False)
            csv = df_future.to_csv().encode('utf-8')
            st.download_button(t('proj_download'), csv, f"forecast_{symbol}.csv", "text/csv")

elif selected_page_key == 'faq':
    st.title(t('faq_title'))
    with st.container(border=True):
        st.subheader(t('faq_step1_title'))
        st.markdown(t('faq_step1_desc'))
        st.subheader(t('faq_step2_title'))
        st.markdown(t('faq_step2_desc'))
        st.subheader(t('faq_step3_title'))
        st.markdown(t('faq_step3_desc'))
        st.subheader(t('faq_step4_title'))
        st.markdown(t('faq_step4_desc'))
        st.subheader(t('faq_step5_title'))
        st.markdown(t('faq_step5_desc'))
        st.subheader(t('faq_step6_title'))
        st.markdown(t('faq_step6_desc'))

elif selected_page_key == 'contact':
    st.title(t('contact_title'))
    with st.container(border=True):
        st.markdown(t('contact_info'))
        st.markdown(f"### {t('contact_name')}")
        st.markdown(f"**{t('contact_job_title')}**")
        st.divider()
        st.markdown(f"**{t('contact_email')} :** Haithem-Berkane@outlook.fr")
        st.markdown(f"**{t('contact_phone')} :** +213 661 338 333")
        st.markdown(f"**{t('contact_address')} :** Algeria")

